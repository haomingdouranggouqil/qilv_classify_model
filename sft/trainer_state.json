{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9411764705882355,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014705882352941176,
      "grad_norm": 15.66616439819336,
      "learning_rate": 2.647058823529412e-06,
      "loss": 9.9988,
      "step": 10
    },
    {
      "epoch": 0.029411764705882353,
      "grad_norm": 19.3574161529541,
      "learning_rate": 5.588235294117647e-06,
      "loss": 9.9708,
      "step": 20
    },
    {
      "epoch": 0.04411764705882353,
      "grad_norm": 12.75083065032959,
      "learning_rate": 8.529411764705883e-06,
      "loss": 8.6638,
      "step": 30
    },
    {
      "epoch": 0.058823529411764705,
      "grad_norm": 10.839678764343262,
      "learning_rate": 1.1470588235294118e-05,
      "loss": 6.309,
      "step": 40
    },
    {
      "epoch": 0.07352941176470588,
      "grad_norm": 8.634259223937988,
      "learning_rate": 1.4411764705882352e-05,
      "loss": 4.2436,
      "step": 50
    },
    {
      "epoch": 0.08823529411764706,
      "grad_norm": 7.701528549194336,
      "learning_rate": 1.735294117647059e-05,
      "loss": 2.7344,
      "step": 60
    },
    {
      "epoch": 0.10294117647058823,
      "grad_norm": 10.262763977050781,
      "learning_rate": 2.0294117647058825e-05,
      "loss": 1.9294,
      "step": 70
    },
    {
      "epoch": 0.11764705882352941,
      "grad_norm": 7.297530651092529,
      "learning_rate": 2.323529411764706e-05,
      "loss": 1.4047,
      "step": 80
    },
    {
      "epoch": 0.1323529411764706,
      "grad_norm": 11.089235305786133,
      "learning_rate": 2.6176470588235295e-05,
      "loss": 1.1148,
      "step": 90
    },
    {
      "epoch": 0.14705882352941177,
      "grad_norm": 9.711017608642578,
      "learning_rate": 2.9117647058823534e-05,
      "loss": 0.9695,
      "step": 100
    },
    {
      "epoch": 0.16176470588235295,
      "grad_norm": 7.0297040939331055,
      "learning_rate": 3.205882352941177e-05,
      "loss": 0.8743,
      "step": 110
    },
    {
      "epoch": 0.17647058823529413,
      "grad_norm": 9.294947624206543,
      "learning_rate": 3.5e-05,
      "loss": 0.837,
      "step": 120
    },
    {
      "epoch": 0.19117647058823528,
      "grad_norm": 4.361112594604492,
      "learning_rate": 3.794117647058824e-05,
      "loss": 0.7537,
      "step": 130
    },
    {
      "epoch": 0.20588235294117646,
      "grad_norm": 11.532379150390625,
      "learning_rate": 4.0882352941176474e-05,
      "loss": 0.8213,
      "step": 140
    },
    {
      "epoch": 0.22058823529411764,
      "grad_norm": 5.465789318084717,
      "learning_rate": 4.382352941176471e-05,
      "loss": 0.7143,
      "step": 150
    },
    {
      "epoch": 0.23529411764705882,
      "grad_norm": 5.659839630126953,
      "learning_rate": 4.6764705882352944e-05,
      "loss": 0.695,
      "step": 160
    },
    {
      "epoch": 0.25,
      "grad_norm": 6.161053657531738,
      "learning_rate": 4.970588235294118e-05,
      "loss": 0.6757,
      "step": 170
    },
    {
      "epoch": 0.2647058823529412,
      "grad_norm": 5.432236671447754,
      "learning_rate": 5.2647058823529414e-05,
      "loss": 0.7337,
      "step": 180
    },
    {
      "epoch": 0.27941176470588236,
      "grad_norm": 8.154617309570312,
      "learning_rate": 5.558823529411765e-05,
      "loss": 0.7572,
      "step": 190
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 4.940232753753662,
      "learning_rate": 5.852941176470589e-05,
      "loss": 0.6675,
      "step": 200
    },
    {
      "epoch": 0.3088235294117647,
      "grad_norm": 6.353248119354248,
      "learning_rate": 6.147058823529413e-05,
      "loss": 0.6544,
      "step": 210
    },
    {
      "epoch": 0.3235294117647059,
      "grad_norm": 6.385648727416992,
      "learning_rate": 6.441176470588236e-05,
      "loss": 0.6634,
      "step": 220
    },
    {
      "epoch": 0.3382352941176471,
      "grad_norm": 6.297796726226807,
      "learning_rate": 6.73529411764706e-05,
      "loss": 0.6365,
      "step": 230
    },
    {
      "epoch": 0.35294117647058826,
      "grad_norm": 5.496616840362549,
      "learning_rate": 7.029411764705882e-05,
      "loss": 0.7358,
      "step": 240
    },
    {
      "epoch": 0.36764705882352944,
      "grad_norm": 5.127566337585449,
      "learning_rate": 7.323529411764705e-05,
      "loss": 0.6561,
      "step": 250
    },
    {
      "epoch": 0.38235294117647056,
      "grad_norm": 5.4724578857421875,
      "learning_rate": 7.617647058823529e-05,
      "loss": 0.6344,
      "step": 260
    },
    {
      "epoch": 0.39705882352941174,
      "grad_norm": 3.8496897220611572,
      "learning_rate": 7.911764705882354e-05,
      "loss": 0.6891,
      "step": 270
    },
    {
      "epoch": 0.4117647058823529,
      "grad_norm": 6.1552534103393555,
      "learning_rate": 8.205882352941177e-05,
      "loss": 0.627,
      "step": 280
    },
    {
      "epoch": 0.4264705882352941,
      "grad_norm": 3.753030300140381,
      "learning_rate": 8.5e-05,
      "loss": 0.6674,
      "step": 290
    },
    {
      "epoch": 0.4411764705882353,
      "grad_norm": 3.6373050212860107,
      "learning_rate": 8.794117647058824e-05,
      "loss": 0.6454,
      "step": 300
    },
    {
      "epoch": 0.45588235294117646,
      "grad_norm": 4.478955268859863,
      "learning_rate": 9.088235294117648e-05,
      "loss": 0.6243,
      "step": 310
    },
    {
      "epoch": 0.47058823529411764,
      "grad_norm": 5.381415367126465,
      "learning_rate": 9.382352941176471e-05,
      "loss": 0.6775,
      "step": 320
    },
    {
      "epoch": 0.4852941176470588,
      "grad_norm": 3.861673355102539,
      "learning_rate": 9.676470588235295e-05,
      "loss": 0.6892,
      "step": 330
    },
    {
      "epoch": 0.5,
      "grad_norm": 3.609593391418457,
      "learning_rate": 9.970588235294118e-05,
      "loss": 0.5898,
      "step": 340
    },
    {
      "epoch": 0.5147058823529411,
      "grad_norm": 3.703641891479492,
      "learning_rate": 9.99978655851684e-05,
      "loss": 0.6043,
      "step": 350
    },
    {
      "epoch": 0.5294117647058824,
      "grad_norm": 4.033573150634766,
      "learning_rate": 9.999048759501343e-05,
      "loss": 0.6183,
      "step": 360
    },
    {
      "epoch": 0.5441176470588235,
      "grad_norm": 7.97586727142334,
      "learning_rate": 9.997784045621205e-05,
      "loss": 0.5865,
      "step": 370
    },
    {
      "epoch": 0.5588235294117647,
      "grad_norm": 5.396699905395508,
      "learning_rate": 9.995992550181094e-05,
      "loss": 0.6311,
      "step": 380
    },
    {
      "epoch": 0.5735294117647058,
      "grad_norm": 4.592517375946045,
      "learning_rate": 9.99367446201005e-05,
      "loss": 0.561,
      "step": 390
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 4.119670867919922,
      "learning_rate": 9.990830025441579e-05,
      "loss": 0.6092,
      "step": 400
    },
    {
      "epoch": 0.6029411764705882,
      "grad_norm": 6.17152214050293,
      "learning_rate": 9.987459540287904e-05,
      "loss": 0.693,
      "step": 410
    },
    {
      "epoch": 0.6176470588235294,
      "grad_norm": 4.492884635925293,
      "learning_rate": 9.983563361808357e-05,
      "loss": 0.5742,
      "step": 420
    },
    {
      "epoch": 0.6323529411764706,
      "grad_norm": 3.6924009323120117,
      "learning_rate": 9.979141900671938e-05,
      "loss": 0.5379,
      "step": 430
    },
    {
      "epoch": 0.6470588235294118,
      "grad_norm": 2.7013580799102783,
      "learning_rate": 9.974195622914028e-05,
      "loss": 0.5336,
      "step": 440
    },
    {
      "epoch": 0.6617647058823529,
      "grad_norm": 4.514355182647705,
      "learning_rate": 9.968725049887269e-05,
      "loss": 0.513,
      "step": 450
    },
    {
      "epoch": 0.6764705882352942,
      "grad_norm": 2.310624122619629,
      "learning_rate": 9.962730758206611e-05,
      "loss": 0.4593,
      "step": 460
    },
    {
      "epoch": 0.6911764705882353,
      "grad_norm": 5.389730930328369,
      "learning_rate": 9.956213379688532e-05,
      "loss": 0.5525,
      "step": 470
    },
    {
      "epoch": 0.7058823529411765,
      "grad_norm": 3.9806294441223145,
      "learning_rate": 9.949173601284448e-05,
      "loss": 0.5611,
      "step": 480
    },
    {
      "epoch": 0.7205882352941176,
      "grad_norm": 3.085935115814209,
      "learning_rate": 9.941612165008303e-05,
      "loss": 0.4984,
      "step": 490
    },
    {
      "epoch": 0.7352941176470589,
      "grad_norm": 3.7006165981292725,
      "learning_rate": 9.933529867858357e-05,
      "loss": 0.5006,
      "step": 500
    },
    {
      "epoch": 0.7352941176470589,
      "eval_loss": 0.5381191372871399,
      "eval_runtime": 28.97,
      "eval_samples_per_second": 41.698,
      "eval_steps_per_second": 2.623,
      "step": 500
    },
    {
      "epoch": 0.75,
      "grad_norm": 4.3230299949646,
      "learning_rate": 9.924927561733188e-05,
      "loss": 0.5199,
      "step": 510
    },
    {
      "epoch": 0.7647058823529411,
      "grad_norm": 4.076526641845703,
      "learning_rate": 9.915806153341884e-05,
      "loss": 0.509,
      "step": 520
    },
    {
      "epoch": 0.7794117647058824,
      "grad_norm": 6.744115829467773,
      "learning_rate": 9.906166604108493e-05,
      "loss": 0.4612,
      "step": 530
    },
    {
      "epoch": 0.7941176470588235,
      "grad_norm": 2.9640183448791504,
      "learning_rate": 9.896009930070666e-05,
      "loss": 0.5555,
      "step": 540
    },
    {
      "epoch": 0.8088235294117647,
      "grad_norm": 4.319621562957764,
      "learning_rate": 9.885337201772577e-05,
      "loss": 0.4738,
      "step": 550
    },
    {
      "epoch": 0.8235294117647058,
      "grad_norm": 4.950911045074463,
      "learning_rate": 9.874149544152085e-05,
      "loss": 0.5847,
      "step": 560
    },
    {
      "epoch": 0.8382352941176471,
      "grad_norm": 2.5362987518310547,
      "learning_rate": 9.862448136422148e-05,
      "loss": 0.3921,
      "step": 570
    },
    {
      "epoch": 0.8529411764705882,
      "grad_norm": 3.090670585632324,
      "learning_rate": 9.850234211946549e-05,
      "loss": 0.5665,
      "step": 580
    },
    {
      "epoch": 0.8676470588235294,
      "grad_norm": 3.2568228244781494,
      "learning_rate": 9.83750905810988e-05,
      "loss": 0.5485,
      "step": 590
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 3.5814449787139893,
      "learning_rate": 9.82427401618186e-05,
      "loss": 0.4465,
      "step": 600
    },
    {
      "epoch": 0.8970588235294118,
      "grad_norm": 4.743154525756836,
      "learning_rate": 9.81053048117595e-05,
      "loss": 0.4919,
      "step": 610
    },
    {
      "epoch": 0.9117647058823529,
      "grad_norm": 1.868298053741455,
      "learning_rate": 9.796279901702325e-05,
      "loss": 0.5447,
      "step": 620
    },
    {
      "epoch": 0.9264705882352942,
      "grad_norm": 4.086411476135254,
      "learning_rate": 9.781523779815179e-05,
      "loss": 0.5555,
      "step": 630
    },
    {
      "epoch": 0.9411764705882353,
      "grad_norm": 3.361351728439331,
      "learning_rate": 9.766263670854403e-05,
      "loss": 0.4877,
      "step": 640
    },
    {
      "epoch": 0.9558823529411765,
      "grad_norm": 3.572089910507202,
      "learning_rate": 9.750501183281656e-05,
      "loss": 0.4565,
      "step": 650
    },
    {
      "epoch": 0.9705882352941176,
      "grad_norm": 3.204221725463867,
      "learning_rate": 9.734237978510818e-05,
      "loss": 0.437,
      "step": 660
    },
    {
      "epoch": 0.9852941176470589,
      "grad_norm": 2.722116708755493,
      "learning_rate": 9.717475770732882e-05,
      "loss": 0.5018,
      "step": 670
    },
    {
      "epoch": 1.0,
      "grad_norm": 4.137529373168945,
      "learning_rate": 9.700216326735262e-05,
      "loss": 0.4434,
      "step": 680
    },
    {
      "epoch": 1.0147058823529411,
      "grad_norm": 5.35703706741333,
      "learning_rate": 9.682461465715576e-05,
      "loss": 0.4219,
      "step": 690
    },
    {
      "epoch": 1.0294117647058822,
      "grad_norm": 6.4943318367004395,
      "learning_rate": 9.664213059089896e-05,
      "loss": 0.387,
      "step": 700
    },
    {
      "epoch": 1.0441176470588236,
      "grad_norm": 3.065044641494751,
      "learning_rate": 9.645473030295496e-05,
      "loss": 0.3126,
      "step": 710
    },
    {
      "epoch": 1.0588235294117647,
      "grad_norm": 3.8127033710479736,
      "learning_rate": 9.626243354588107e-05,
      "loss": 0.3584,
      "step": 720
    },
    {
      "epoch": 1.0735294117647058,
      "grad_norm": 4.538595199584961,
      "learning_rate": 9.606526058833735e-05,
      "loss": 0.3416,
      "step": 730
    },
    {
      "epoch": 1.088235294117647,
      "grad_norm": 4.263530731201172,
      "learning_rate": 9.586323221295008e-05,
      "loss": 0.35,
      "step": 740
    },
    {
      "epoch": 1.1029411764705883,
      "grad_norm": 4.46993350982666,
      "learning_rate": 9.56563697141213e-05,
      "loss": 0.4153,
      "step": 750
    },
    {
      "epoch": 1.1176470588235294,
      "grad_norm": 2.8447539806365967,
      "learning_rate": 9.544469489578431e-05,
      "loss": 0.3896,
      "step": 760
    },
    {
      "epoch": 1.1323529411764706,
      "grad_norm": 3.0310938358306885,
      "learning_rate": 9.522823006910537e-05,
      "loss": 0.3091,
      "step": 770
    },
    {
      "epoch": 1.1470588235294117,
      "grad_norm": 5.202378749847412,
      "learning_rate": 9.500699805013218e-05,
      "loss": 0.3456,
      "step": 780
    },
    {
      "epoch": 1.161764705882353,
      "grad_norm": 5.5107550621032715,
      "learning_rate": 9.478102215738892e-05,
      "loss": 0.3724,
      "step": 790
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 3.0328304767608643,
      "learning_rate": 9.45503262094184e-05,
      "loss": 0.4552,
      "step": 800
    },
    {
      "epoch": 1.1911764705882353,
      "grad_norm": 2.9104583263397217,
      "learning_rate": 9.431493452227153e-05,
      "loss": 0.3231,
      "step": 810
    },
    {
      "epoch": 1.2058823529411764,
      "grad_norm": 4.575880527496338,
      "learning_rate": 9.407487190694438e-05,
      "loss": 0.4092,
      "step": 820
    },
    {
      "epoch": 1.2205882352941178,
      "grad_norm": 4.384583950042725,
      "learning_rate": 9.383016366676294e-05,
      "loss": 0.3503,
      "step": 830
    },
    {
      "epoch": 1.2352941176470589,
      "grad_norm": 2.979917526245117,
      "learning_rate": 9.358083559471611e-05,
      "loss": 0.3465,
      "step": 840
    },
    {
      "epoch": 1.25,
      "grad_norm": 4.434230804443359,
      "learning_rate": 9.332691397073707e-05,
      "loss": 0.3792,
      "step": 850
    },
    {
      "epoch": 1.2647058823529411,
      "grad_norm": 3.607274293899536,
      "learning_rate": 9.306842555893328e-05,
      "loss": 0.3532,
      "step": 860
    },
    {
      "epoch": 1.2794117647058822,
      "grad_norm": 2.4263737201690674,
      "learning_rate": 9.280539760476543e-05,
      "loss": 0.4119,
      "step": 870
    },
    {
      "epoch": 1.2941176470588236,
      "grad_norm": 4.225892066955566,
      "learning_rate": 9.253785783217572e-05,
      "loss": 0.2937,
      "step": 880
    },
    {
      "epoch": 1.3088235294117647,
      "grad_norm": 4.818863391876221,
      "learning_rate": 9.226583444066569e-05,
      "loss": 0.3107,
      "step": 890
    },
    {
      "epoch": 1.3235294117647058,
      "grad_norm": 3.031648874282837,
      "learning_rate": 9.198935610232382e-05,
      "loss": 0.3822,
      "step": 900
    },
    {
      "epoch": 1.3382352941176472,
      "grad_norm": 4.163002014160156,
      "learning_rate": 9.17084519588035e-05,
      "loss": 0.3188,
      "step": 910
    },
    {
      "epoch": 1.3529411764705883,
      "grad_norm": 4.979669094085693,
      "learning_rate": 9.14231516182514e-05,
      "loss": 0.3152,
      "step": 920
    },
    {
      "epoch": 1.3676470588235294,
      "grad_norm": 6.273999214172363,
      "learning_rate": 9.113348515218661e-05,
      "loss": 0.335,
      "step": 930
    },
    {
      "epoch": 1.3823529411764706,
      "grad_norm": 4.064239978790283,
      "learning_rate": 9.08394830923311e-05,
      "loss": 0.353,
      "step": 940
    },
    {
      "epoch": 1.3970588235294117,
      "grad_norm": 2.61564302444458,
      "learning_rate": 9.054117642739151e-05,
      "loss": 0.3245,
      "step": 950
    },
    {
      "epoch": 1.4117647058823528,
      "grad_norm": 2.940394401550293,
      "learning_rate": 9.023859659979292e-05,
      "loss": 0.3685,
      "step": 960
    },
    {
      "epoch": 1.4264705882352942,
      "grad_norm": 4.313064098358154,
      "learning_rate": 8.993177550236464e-05,
      "loss": 0.3577,
      "step": 970
    },
    {
      "epoch": 1.4411764705882353,
      "grad_norm": 3.9581871032714844,
      "learning_rate": 8.962074547497869e-05,
      "loss": 0.3102,
      "step": 980
    },
    {
      "epoch": 1.4558823529411764,
      "grad_norm": 4.220587253570557,
      "learning_rate": 8.930553930114103e-05,
      "loss": 0.3677,
      "step": 990
    },
    {
      "epoch": 1.4705882352941178,
      "grad_norm": 3.4832451343536377,
      "learning_rate": 8.898619020453606e-05,
      "loss": 0.3373,
      "step": 1000
    },
    {
      "epoch": 1.4705882352941178,
      "eval_loss": 0.4163192808628082,
      "eval_runtime": 28.947,
      "eval_samples_per_second": 41.731,
      "eval_steps_per_second": 2.625,
      "step": 1000
    },
    {
      "epoch": 1.4852941176470589,
      "grad_norm": 4.331243991851807,
      "learning_rate": 8.866273184552483e-05,
      "loss": 0.3215,
      "step": 1010
    },
    {
      "epoch": 1.5,
      "grad_norm": 6.796475410461426,
      "learning_rate": 8.833519831759702e-05,
      "loss": 0.2972,
      "step": 1020
    },
    {
      "epoch": 1.5147058823529411,
      "grad_norm": 3.4502105712890625,
      "learning_rate": 8.800362414377752e-05,
      "loss": 0.3105,
      "step": 1030
    },
    {
      "epoch": 1.5294117647058822,
      "grad_norm": 2.9566004276275635,
      "learning_rate": 8.766804427298743e-05,
      "loss": 0.3336,
      "step": 1040
    },
    {
      "epoch": 1.5441176470588234,
      "grad_norm": 3.164585590362549,
      "learning_rate": 8.732849407636053e-05,
      "loss": 0.2494,
      "step": 1050
    },
    {
      "epoch": 1.5588235294117647,
      "grad_norm": 2.937474250793457,
      "learning_rate": 8.698500934351488e-05,
      "loss": 0.2844,
      "step": 1060
    },
    {
      "epoch": 1.5735294117647058,
      "grad_norm": 4.83770751953125,
      "learning_rate": 8.663762627878058e-05,
      "loss": 0.3213,
      "step": 1070
    },
    {
      "epoch": 1.5882352941176472,
      "grad_norm": 3.9836888313293457,
      "learning_rate": 8.628638149738371e-05,
      "loss": 0.3304,
      "step": 1080
    },
    {
      "epoch": 1.6029411764705883,
      "grad_norm": 2.675704002380371,
      "learning_rate": 8.593131202158702e-05,
      "loss": 0.3228,
      "step": 1090
    },
    {
      "epoch": 1.6176470588235294,
      "grad_norm": 3.7714643478393555,
      "learning_rate": 8.557245527678752e-05,
      "loss": 0.3116,
      "step": 1100
    },
    {
      "epoch": 1.6323529411764706,
      "grad_norm": 4.648597717285156,
      "learning_rate": 8.520984908757193e-05,
      "loss": 0.3032,
      "step": 1110
    },
    {
      "epoch": 1.6470588235294117,
      "grad_norm": 3.563762664794922,
      "learning_rate": 8.484353167372969e-05,
      "loss": 0.3368,
      "step": 1120
    },
    {
      "epoch": 1.6617647058823528,
      "grad_norm": 2.679582118988037,
      "learning_rate": 8.447354164622457e-05,
      "loss": 0.2967,
      "step": 1130
    },
    {
      "epoch": 1.6764705882352942,
      "grad_norm": 2.469435691833496,
      "learning_rate": 8.409991800312493e-05,
      "loss": 0.267,
      "step": 1140
    },
    {
      "epoch": 1.6911764705882353,
      "grad_norm": 5.13684606552124,
      "learning_rate": 8.372270012549322e-05,
      "loss": 0.2628,
      "step": 1150
    },
    {
      "epoch": 1.7058823529411766,
      "grad_norm": 3.67920184135437,
      "learning_rate": 8.334192777323507e-05,
      "loss": 0.2499,
      "step": 1160
    },
    {
      "epoch": 1.7205882352941178,
      "grad_norm": 3.653653860092163,
      "learning_rate": 8.295764108090849e-05,
      "loss": 0.3278,
      "step": 1170
    },
    {
      "epoch": 1.7352941176470589,
      "grad_norm": 5.078189849853516,
      "learning_rate": 8.256988055349357e-05,
      "loss": 0.2993,
      "step": 1180
    },
    {
      "epoch": 1.75,
      "grad_norm": 4.478072166442871,
      "learning_rate": 8.217868706212312e-05,
      "loss": 0.406,
      "step": 1190
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 2.8486013412475586,
      "learning_rate": 8.178410183977479e-05,
      "loss": 0.3198,
      "step": 1200
    },
    {
      "epoch": 1.7794117647058822,
      "grad_norm": 2.6020731925964355,
      "learning_rate": 8.138616647692483e-05,
      "loss": 0.2697,
      "step": 1210
    },
    {
      "epoch": 1.7941176470588234,
      "grad_norm": 2.581821918487549,
      "learning_rate": 8.098492291716454e-05,
      "loss": 0.2736,
      "step": 1220
    },
    {
      "epoch": 1.8088235294117647,
      "grad_norm": 2.5369348526000977,
      "learning_rate": 8.058041345277911e-05,
      "loss": 0.3005,
      "step": 1230
    },
    {
      "epoch": 1.8235294117647058,
      "grad_norm": 5.4221320152282715,
      "learning_rate": 8.017268072029002e-05,
      "loss": 0.2876,
      "step": 1240
    },
    {
      "epoch": 1.8382352941176472,
      "grad_norm": 3.144155740737915,
      "learning_rate": 7.976176769596094e-05,
      "loss": 0.3152,
      "step": 1250
    },
    {
      "epoch": 1.8529411764705883,
      "grad_norm": 3.773381233215332,
      "learning_rate": 7.93477176912679e-05,
      "loss": 0.3473,
      "step": 1260
    },
    {
      "epoch": 1.8676470588235294,
      "grad_norm": 2.68412446975708,
      "learning_rate": 7.893057434833417e-05,
      "loss": 0.2435,
      "step": 1270
    },
    {
      "epoch": 1.8823529411764706,
      "grad_norm": 3.9256248474121094,
      "learning_rate": 7.85103816353302e-05,
      "loss": 0.2715,
      "step": 1280
    },
    {
      "epoch": 1.8970588235294117,
      "grad_norm": 3.714648723602295,
      "learning_rate": 7.808718384183933e-05,
      "loss": 0.2887,
      "step": 1290
    },
    {
      "epoch": 1.9117647058823528,
      "grad_norm": 4.447189807891846,
      "learning_rate": 7.766102557418945e-05,
      "loss": 0.2963,
      "step": 1300
    },
    {
      "epoch": 1.9264705882352942,
      "grad_norm": 4.579947471618652,
      "learning_rate": 7.723195175075136e-05,
      "loss": 0.2407,
      "step": 1310
    },
    {
      "epoch": 1.9411764705882353,
      "grad_norm": 2.810185670852661,
      "learning_rate": 7.680000759720427e-05,
      "loss": 0.3019,
      "step": 1320
    },
    {
      "epoch": 1.9558823529411766,
      "grad_norm": 3.622687339782715,
      "learning_rate": 7.63652386417689e-05,
      "loss": 0.2722,
      "step": 1330
    },
    {
      "epoch": 1.9705882352941178,
      "grad_norm": 2.993274450302124,
      "learning_rate": 7.592769071040861e-05,
      "loss": 0.3136,
      "step": 1340
    },
    {
      "epoch": 1.9852941176470589,
      "grad_norm": 3.6238837242126465,
      "learning_rate": 7.548740992199922e-05,
      "loss": 0.2766,
      "step": 1350
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.142776012420654,
      "learning_rate": 7.504444268346798e-05,
      "loss": 0.3247,
      "step": 1360
    },
    {
      "epoch": 2.014705882352941,
      "grad_norm": 3.158154249191284,
      "learning_rate": 7.459883568490206e-05,
      "loss": 0.1254,
      "step": 1370
    },
    {
      "epoch": 2.0294117647058822,
      "grad_norm": 4.043147087097168,
      "learning_rate": 7.415063589462741e-05,
      "loss": 0.1095,
      "step": 1380
    },
    {
      "epoch": 2.0441176470588234,
      "grad_norm": 0.48241540789604187,
      "learning_rate": 7.369989055425802e-05,
      "loss": 0.0627,
      "step": 1390
    },
    {
      "epoch": 2.0588235294117645,
      "grad_norm": 2.0339062213897705,
      "learning_rate": 7.324664717371652e-05,
      "loss": 0.1645,
      "step": 1400
    },
    {
      "epoch": 2.073529411764706,
      "grad_norm": 1.9041779041290283,
      "learning_rate": 7.279095352622662e-05,
      "loss": 0.0896,
      "step": 1410
    },
    {
      "epoch": 2.088235294117647,
      "grad_norm": 1.9393749237060547,
      "learning_rate": 7.233285764327752e-05,
      "loss": 0.1252,
      "step": 1420
    },
    {
      "epoch": 2.1029411764705883,
      "grad_norm": 4.517743110656738,
      "learning_rate": 7.187240780956133e-05,
      "loss": 0.1045,
      "step": 1430
    },
    {
      "epoch": 2.1176470588235294,
      "grad_norm": 3.058960437774658,
      "learning_rate": 7.140965255788366e-05,
      "loss": 0.0967,
      "step": 1440
    },
    {
      "epoch": 2.1323529411764706,
      "grad_norm": 3.5581841468811035,
      "learning_rate": 7.09446406640482e-05,
      "loss": 0.0903,
      "step": 1450
    },
    {
      "epoch": 2.1470588235294117,
      "grad_norm": 0.3123958706855774,
      "learning_rate": 7.047742114171553e-05,
      "loss": 0.0692,
      "step": 1460
    },
    {
      "epoch": 2.161764705882353,
      "grad_norm": 4.422861576080322,
      "learning_rate": 7.000804323723691e-05,
      "loss": 0.1057,
      "step": 1470
    },
    {
      "epoch": 2.176470588235294,
      "grad_norm": 2.7998316287994385,
      "learning_rate": 6.953655642446368e-05,
      "loss": 0.1377,
      "step": 1480
    },
    {
      "epoch": 2.1911764705882355,
      "grad_norm": 8.940032005310059,
      "learning_rate": 6.906301039953248e-05,
      "loss": 0.1252,
      "step": 1490
    },
    {
      "epoch": 2.2058823529411766,
      "grad_norm": 1.8570834398269653,
      "learning_rate": 6.858745507562708e-05,
      "loss": 0.0706,
      "step": 1500
    },
    {
      "epoch": 2.2058823529411766,
      "eval_loss": 0.47782254219055176,
      "eval_runtime": 28.947,
      "eval_samples_per_second": 41.732,
      "eval_steps_per_second": 2.625,
      "step": 1500
    },
    {
      "epoch": 2.2205882352941178,
      "grad_norm": 2.1907799243927,
      "learning_rate": 6.810994057771751e-05,
      "loss": 0.0983,
      "step": 1510
    },
    {
      "epoch": 2.235294117647059,
      "grad_norm": 4.197333812713623,
      "learning_rate": 6.763051723727662e-05,
      "loss": 0.0819,
      "step": 1520
    },
    {
      "epoch": 2.25,
      "grad_norm": 1.1728544235229492,
      "learning_rate": 6.714923558697512e-05,
      "loss": 0.0852,
      "step": 1530
    },
    {
      "epoch": 2.264705882352941,
      "grad_norm": 5.655327320098877,
      "learning_rate": 6.666614635535507e-05,
      "loss": 0.0576,
      "step": 1540
    },
    {
      "epoch": 2.2794117647058822,
      "grad_norm": 5.4379777908325195,
      "learning_rate": 6.618130046148319e-05,
      "loss": 0.1155,
      "step": 1550
    },
    {
      "epoch": 2.2941176470588234,
      "grad_norm": 5.558091640472412,
      "learning_rate": 6.569474900958366e-05,
      "loss": 0.0795,
      "step": 1560
    },
    {
      "epoch": 2.3088235294117645,
      "grad_norm": 3.118036985397339,
      "learning_rate": 6.520654328365163e-05,
      "loss": 0.1235,
      "step": 1570
    },
    {
      "epoch": 2.323529411764706,
      "grad_norm": 5.093050003051758,
      "learning_rate": 6.471673474204777e-05,
      "loss": 0.1154,
      "step": 1580
    },
    {
      "epoch": 2.338235294117647,
      "grad_norm": 1.5620872974395752,
      "learning_rate": 6.422537501207435e-05,
      "loss": 0.0759,
      "step": 1590
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 6.71006965637207,
      "learning_rate": 6.373251588453361e-05,
      "loss": 0.108,
      "step": 1600
    },
    {
      "epoch": 2.3676470588235294,
      "grad_norm": 7.9514031410217285,
      "learning_rate": 6.323820930826879e-05,
      "loss": 0.1229,
      "step": 1610
    },
    {
      "epoch": 2.3823529411764706,
      "grad_norm": 2.4801278114318848,
      "learning_rate": 6.274250738468866e-05,
      "loss": 0.079,
      "step": 1620
    },
    {
      "epoch": 2.3970588235294117,
      "grad_norm": 5.229593276977539,
      "learning_rate": 6.224546236227574e-05,
      "loss": 0.0494,
      "step": 1630
    },
    {
      "epoch": 2.411764705882353,
      "grad_norm": 6.729365825653076,
      "learning_rate": 6.174712663107934e-05,
      "loss": 0.0752,
      "step": 1640
    },
    {
      "epoch": 2.426470588235294,
      "grad_norm": 8.588828086853027,
      "learning_rate": 6.124755271719325e-05,
      "loss": 0.1552,
      "step": 1650
    },
    {
      "epoch": 2.4411764705882355,
      "grad_norm": 3.7495510578155518,
      "learning_rate": 6.074679327721959e-05,
      "loss": 0.0587,
      "step": 1660
    },
    {
      "epoch": 2.4558823529411766,
      "grad_norm": 4.1401753425598145,
      "learning_rate": 6.024490109271842e-05,
      "loss": 0.0398,
      "step": 1670
    },
    {
      "epoch": 2.4705882352941178,
      "grad_norm": 2.8591909408569336,
      "learning_rate": 5.9741929064644576e-05,
      "loss": 0.0805,
      "step": 1680
    },
    {
      "epoch": 2.485294117647059,
      "grad_norm": 7.669816017150879,
      "learning_rate": 5.92379302077716e-05,
      "loss": 0.1082,
      "step": 1690
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.9669687747955322,
      "learning_rate": 5.873295764510395e-05,
      "loss": 0.1029,
      "step": 1700
    },
    {
      "epoch": 2.514705882352941,
      "grad_norm": 1.1206202507019043,
      "learning_rate": 5.822706460227758e-05,
      "loss": 0.0965,
      "step": 1710
    },
    {
      "epoch": 2.5294117647058822,
      "grad_norm": 2.3494203090667725,
      "learning_rate": 5.772030440194991e-05,
      "loss": 0.1292,
      "step": 1720
    },
    {
      "epoch": 2.5441176470588234,
      "grad_norm": 7.076660633087158,
      "learning_rate": 5.7212730458179295e-05,
      "loss": 0.0831,
      "step": 1730
    },
    {
      "epoch": 2.5588235294117645,
      "grad_norm": 3.275881767272949,
      "learning_rate": 5.670439627079517e-05,
      "loss": 0.0676,
      "step": 1740
    },
    {
      "epoch": 2.5735294117647056,
      "grad_norm": 3.2555251121520996,
      "learning_rate": 5.61953554197589e-05,
      "loss": 0.0872,
      "step": 1750
    },
    {
      "epoch": 2.588235294117647,
      "grad_norm": 6.406494140625,
      "learning_rate": 5.568566155951639e-05,
      "loss": 0.0862,
      "step": 1760
    },
    {
      "epoch": 2.6029411764705883,
      "grad_norm": 1.4771493673324585,
      "learning_rate": 5.517536841334268e-05,
      "loss": 0.0602,
      "step": 1770
    },
    {
      "epoch": 2.6176470588235294,
      "grad_norm": 5.800670146942139,
      "learning_rate": 5.466452976767933e-05,
      "loss": 0.1095,
      "step": 1780
    },
    {
      "epoch": 2.6323529411764706,
      "grad_norm": 2.7167551517486572,
      "learning_rate": 5.41531994664652e-05,
      "loss": 0.0774,
      "step": 1790
    },
    {
      "epoch": 2.6470588235294117,
      "grad_norm": 3.605926513671875,
      "learning_rate": 5.364143140546116e-05,
      "loss": 0.0599,
      "step": 1800
    },
    {
      "epoch": 2.661764705882353,
      "grad_norm": 11.724360466003418,
      "learning_rate": 5.312927952656929e-05,
      "loss": 0.0905,
      "step": 1810
    },
    {
      "epoch": 2.6764705882352944,
      "grad_norm": 2.1298792362213135,
      "learning_rate": 5.26167978121472e-05,
      "loss": 0.0527,
      "step": 1820
    },
    {
      "epoch": 2.6911764705882355,
      "grad_norm": 5.92891788482666,
      "learning_rate": 5.210404027931818e-05,
      "loss": 0.0777,
      "step": 1830
    },
    {
      "epoch": 2.7058823529411766,
      "grad_norm": 6.113384246826172,
      "learning_rate": 5.159106097427763e-05,
      "loss": 0.0886,
      "step": 1840
    },
    {
      "epoch": 2.7205882352941178,
      "grad_norm": 4.7293572425842285,
      "learning_rate": 5.107791396659637e-05,
      "loss": 0.1497,
      "step": 1850
    },
    {
      "epoch": 2.735294117647059,
      "grad_norm": 2.1215221881866455,
      "learning_rate": 5.0564653343521664e-05,
      "loss": 0.0978,
      "step": 1860
    },
    {
      "epoch": 2.75,
      "grad_norm": 4.532075881958008,
      "learning_rate": 5.0051333204276086e-05,
      "loss": 0.0608,
      "step": 1870
    },
    {
      "epoch": 2.764705882352941,
      "grad_norm": 2.176555871963501,
      "learning_rate": 4.953800765435547e-05,
      "loss": 0.0556,
      "step": 1880
    },
    {
      "epoch": 2.7794117647058822,
      "grad_norm": 1.2393282651901245,
      "learning_rate": 4.902473079982591e-05,
      "loss": 0.0736,
      "step": 1890
    },
    {
      "epoch": 2.7941176470588234,
      "grad_norm": 6.298925876617432,
      "learning_rate": 4.8511556741620874e-05,
      "loss": 0.0867,
      "step": 1900
    },
    {
      "epoch": 2.8088235294117645,
      "grad_norm": 5.285828590393066,
      "learning_rate": 4.799853956983879e-05,
      "loss": 0.0711,
      "step": 1910
    },
    {
      "epoch": 2.8235294117647056,
      "grad_norm": 4.428553104400635,
      "learning_rate": 4.748573335804175e-05,
      "loss": 0.1196,
      "step": 1920
    },
    {
      "epoch": 2.838235294117647,
      "grad_norm": 5.0376877784729,
      "learning_rate": 4.69731921575561e-05,
      "loss": 0.0667,
      "step": 1930
    },
    {
      "epoch": 2.8529411764705883,
      "grad_norm": 5.15952730178833,
      "learning_rate": 4.646096999177511e-05,
      "loss": 0.0865,
      "step": 1940
    },
    {
      "epoch": 2.8676470588235294,
      "grad_norm": 4.762948513031006,
      "learning_rate": 4.594912085046486e-05,
      "loss": 0.0608,
      "step": 1950
    },
    {
      "epoch": 2.8823529411764706,
      "grad_norm": 7.233273983001709,
      "learning_rate": 4.543769868407354e-05,
      "loss": 0.0969,
      "step": 1960
    },
    {
      "epoch": 2.8970588235294117,
      "grad_norm": 9.830513000488281,
      "learning_rate": 4.492675739804486e-05,
      "loss": 0.0596,
      "step": 1970
    },
    {
      "epoch": 2.911764705882353,
      "grad_norm": 5.649702072143555,
      "learning_rate": 4.441635084713629e-05,
      "loss": 0.0899,
      "step": 1980
    },
    {
      "epoch": 2.9264705882352944,
      "grad_norm": 3.514350652694702,
      "learning_rate": 4.390653282974264e-05,
      "loss": 0.0742,
      "step": 1990
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 2.668252944946289,
      "learning_rate": 4.339735708222544e-05,
      "loss": 0.0665,
      "step": 2000
    },
    {
      "epoch": 2.9411764705882355,
      "eval_loss": 0.525897204875946,
      "eval_runtime": 28.9438,
      "eval_samples_per_second": 41.736,
      "eval_steps_per_second": 2.626,
      "step": 2000
    }
  ],
  "logging_steps": 10,
  "max_steps": 3400,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2186735038693376e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
